{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-XqBMN29MCK"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from itertools import chain\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.utils import shuffle\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12618,
     "status": "ok",
     "timestamp": 1590417455677,
     "user": {
      "displayName": "任一",
      "photoUrl": "",
      "userId": "04098430598358376154"
     },
     "user_tz": -480
    },
    "id": "uTfbPsj5r2rC",
    "outputId": "b61677ad-3ffa-4ddd-bf12-af93aace340a"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgcuHBWN9MCO"
   },
   "outputs": [],
   "source": [
    "train_df = shuffle(pd.read_csv('./data/data_train.csv'))\n",
    "test_df = pd.read_csv('./data/data_test.csv')\n",
    "with open('./data/stopwords.txt', encoding='utf8') as f:\n",
    "    stop_words = set([x.strip() for x in f.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jEAhRoh-9MCQ"
   },
   "outputs": [],
   "source": [
    "train_corpus = [x.split() for x in train_df['Text'].to_list()]\n",
    "train_labels = train_df['MaxLabel'].to_list()\n",
    "test_corpus =  [x.split() for x in test_df['Text'].to_list()]\n",
    "test_labels = test_df['MaxLabel'].to_list()\n",
    "test_labels_distribution = test_df.iloc[:, 3:11].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F0gN8TiEuF4c"
   },
   "outputs": [],
   "source": [
    "tmp_train_corpus = list()\n",
    "tmp_test_corpus = list()\n",
    "for s in train_corpus:\n",
    "  tmp = list()\n",
    "  for x in s:\n",
    "    if x not in stop_words:\n",
    "      tmp.append(x)\n",
    "  tmp_train_corpus.append(tmp)\n",
    "for s in test_corpus:\n",
    "  tmp = list()\n",
    "  for x in s:\n",
    "    if x not in stop_words:\n",
    "      tmp.append(x)\n",
    "  tmp_test_corpus.append(tmp)\n",
    "train_corpus = tmp_train_corpus\n",
    "test_corpus = tmp_test_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13561,
     "status": "ok",
     "timestamp": 1590417456643,
     "user": {
      "displayName": "任一",
      "photoUrl": "",
      "userId": "04098430598358376154"
     },
     "user_tz": -480
    },
    "id": "ubRVOZBc9MCV",
    "outputId": "391da0af-8155-4ef1-c4c3-2d60e50cd327"
   },
   "outputs": [],
   "source": [
    "train_corpus_max_length = np.max(([len(x) for x in train_corpus]))\n",
    "# padding all sentences to the same length(i.e. the max sentence length in the corpus)\n",
    "for s in train_corpus:\n",
    "    sentence_length = len(s)\n",
    "    for i in range(train_corpus_max_length - sentence_length):\n",
    "        s.append('')\n",
    "train_sentence_num = len(train_corpus)\n",
    "train_sentence_length = len(train_corpus[0])\n",
    "print('train sentence count:', train_sentence_num)\n",
    "print('train sentence length:', train_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KqsjwChP9MCb"
   },
   "outputs": [],
   "source": [
    "# index the words\n",
    "word_to_ix = np.load('./data/word_to_ix.npy', allow_pickle=True).item() # index the words\n",
    "vocab_size = len(set(chain.from_iterable(train_corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rhjAV08S9MCg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 128,
     "status": "ok",
     "timestamp": 1590418347147,
     "user": {
      "displayName": "任一",
      "photoUrl": "",
      "userId": "04098430598358376154"
     },
     "user_tz": -480
    },
    "id": "Mky5fO8t9MCi",
    "outputId": "326743d4-efad-4a84-ec73-2edc1f67b475"
   },
   "outputs": [],
   "source": [
    "train_index = torch.zeros([0, train_sentence_length], dtype=torch.long)\n",
    "for s in train_corpus:\n",
    "    ids = torch.tensor([word_to_ix[w] for w in s], dtype=torch.long)\n",
    "    ids = ids.unsqueeze(dim = 0)\n",
    "    train_index = torch.cat((train_index, ids), dim = 0)\n",
    "train_index = train_index.long()[:, 0:1000]\n",
    "train_index.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 92,
     "status": "ok",
     "timestamp": 1590417531047,
     "user": {
      "displayName": "任一",
      "photoUrl": "",
      "userId": "04098430598358376154"
     },
     "user_tz": -480
    },
    "id": "w-EjLtCQ9MCl",
    "outputId": "f3d282b0-ccb6-43be-d0ff-c19d0c7ee9e1"
   },
   "outputs": [],
   "source": [
    "test_corpus_max_length = np.max([len(x) for x in test_corpus])\n",
    "# padding all sentences to the same length(i.e. the max sentence length in the corpus)\n",
    "for s in test_corpus:\n",
    "    sentence_length = len(s)\n",
    "    for i in range(test_corpus_max_length - sentence_length):\n",
    "        s.append('')\n",
    "test_sentence_num = len(test_corpus)\n",
    "test_sentence_length = len(test_corpus[0])\n",
    "print('test sentence count:', test_sentence_num)\n",
    "print('test sentence length:', test_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 85,
     "status": "ok",
     "timestamp": 1590417531048,
     "user": {
      "displayName": "任一",
      "photoUrl": "",
      "userId": "04098430598358376154"
     },
     "user_tz": -480
    },
    "id": "Zke6Uzkr9MCo",
    "outputId": "f143cc71-3d57-4904-c189-6ee13e85f4a1",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "test_index = torch.zeros([0, test_sentence_length], dtype=torch.long)\n",
    "for s in test_corpus:\n",
    "    ids_list = list()\n",
    "    not_found_num = 0\n",
    "    for w in s:\n",
    "        if w in word_to_ix:\n",
    "            ids_list.append(word_to_ix[w])\n",
    "        else:\n",
    "            not_found_num += 1\n",
    "            # ids_list.append(word_to_ix[''])\n",
    "    for i in range(not_found_num):\n",
    "      ids_list.append(word_to_ix[''])\n",
    "    ids = torch.tensor(ids_list, dtype=torch.long)\n",
    "    ids = ids.unsqueeze(dim = 0)\n",
    "    test_index = torch.cat((test_index, ids), dim = 0)\n",
    "test_index = test_index.long()[:, 0:1000]\n",
    "test_index.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tpjyJIW69MCq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YeNCJtr89MCs"
   },
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "train_length = len(train_labels)\n",
    "mid = int(0.8 * train_length)\n",
    "train_set = torch.utils.data.TensorDataset(train_index[0:mid], torch.tensor(train_labels[0:mid]).long())\n",
    "test_set = torch.utils.data.TensorDataset(test_index, torch.tensor(test_labels).long())\n",
    "dev_set = torch.utils.data.TensorDataset(train_index[mid:train_length], torch.tensor(train_labels[mid:train_length]).long())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bF0BzlJS9MCy"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ku6Lp9Sr9MC2"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Net(nn.Module):\n",
    "    sentence_length = -1\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 8)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "    def forward(self, x):\n",
    "        embeds = self.embeddings(x)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        tag = self.dropout(self.fc(lstm_out[:, -1, :].squeeze(dim=1)))\n",
    "        tag_prob = nn.functional.softmax(tag, dim = 1)\n",
    "        return tag_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G1pyLUQC9MC4"
   },
   "outputs": [],
   "source": [
    "def test_accuracy(loader, net, length):\n",
    "    '''\n",
    "    used in dev set accuracy calculating\n",
    "    '''\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.train(False)\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(tqdm(loader)):\n",
    "            # inputs, label = data\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0) # batch size\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / (0.0 + total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rqCAnccuawcP"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "lr = 0.01\n",
    "batch_size = 4\n",
    "dev_patience = 25\n",
    "hidden_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kOBTfQI49MC6"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1)\n",
    "dev_loader = torch.utils.data.DataLoader(dev_set, batch_size=batch_size)\n",
    "net = Net(vocab_size, embedding_dim, hidden_dim)\n",
    "net.embeddings = nn.Embedding.from_pretrained(torch.load('./data/word_vec.pt'))\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, weight_decay = 0.01)\n",
    "model_path = './model/RNN_EMBED_cuda.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2096,
     "status": "ok",
     "timestamp": 1590418463838,
     "user": {
      "displayName": "任一",
      "photoUrl": "",
      "userId": "04098430598358376154"
     },
     "user_tz": -480
    },
    "id": "tLnPRYxUneNK",
    "outputId": "d8a09521-a7ef-4613-ca61-a2003797306f"
   },
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_DcIqxu09MC8"
   },
   "outputs": [],
   "source": [
    "def check_dev_patience(acc_list, patience = 5):\n",
    "    if len(acc_list) <= patience:\n",
    "        return True\n",
    "    check_list = acc_list[len(acc_list)-patience:len(acc_list)]\n",
    "    for i in range(patience - 2):\n",
    "        if check_list[i] - check_list[i + 1] >= 0.01 and check_list[i + 1] - check_list[i + 2] >= 0.01:\n",
    "            return False\n",
    "    if np.std(check_list) < 1e-4:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57441,
     "status": "ok",
     "timestamp": 1590418519193,
     "user": {
      "displayName": "任一",
      "photoUrl": "",
      "userId": "04098430598358376154"
     },
     "user_tz": -480
    },
    "id": "F2RibVn89MC-",
    "outputId": "ad7cedd9-8fcc-43c6-950a-d733e1946845"
   },
   "outputs": [],
   "source": [
    "print('\\nbefore training test acc:', test_accuracy(test_loader, net, test_sentence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 504475,
     "status": "ok",
     "timestamp": 1590418966235,
     "user": {
      "displayName": "任一",
      "photoUrl": "",
      "userId": "04098430598358376154"
     },
     "user_tz": -480
    },
    "id": "LJrXPlNc9MDC",
    "outputId": "b067fe8f-83cd-49c5-93f4-da40e8f03378",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "loss_batch = 25\n",
    "dev_acc_list = [0] # initialize with a zero, easy to compare before first dev acc comes in\n",
    "loss_list = []\n",
    "epoch_list = []\n",
    "trained_epoch_num = 0\n",
    "start_time = time()\n",
    "print('Start Training, lr=%f, bs=%d, embedding dim=%d from pretrained'%(lr, batch_size, embedding_dim))\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    try:\n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0\n",
    "        cnt = 0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            net.train(True)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            cnt += 1\n",
    "            if i % loss_batch == loss_batch - 1:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / loss_batch))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        dev_accuracy = test_accuracy(dev_loader, net, train_sentence_length)\n",
    "        print('epoch %d loss: %.4f, dev acc = %.3f%%' % (epoch + 1, epoch_loss / cnt, dev_accuracy * 100))\n",
    "        if dev_accuracy > max(dev_acc_list):\n",
    "            print('New Model Saved!')\n",
    "            torch.save(net.state_dict(), model_path)\n",
    "        dev_acc_list.append(dev_accuracy)\n",
    "        loss_list.append(epoch_loss / cnt)\n",
    "        epoch_list.append(epoch + 1)\n",
    "        no_big_improve_on_dev = check_dev_patience(dev_acc_list, dev_patience)\n",
    "        if not no_big_improve_on_dev:\n",
    "            print('No significant improve on dev set, early stopped automatically!')\n",
    "            break\n",
    "        trained_epoch_num += 1\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "      break\n",
    "print('Finished Training, trained for %d epochs, total time = %.2fs, avg time per epoch = %.2fs' % (trained_epoch_num, time() - start_time, (time() - start_time) / trained_epoch_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6963,
     "status": "ok",
     "timestamp": 1590419013934,
     "user": {
      "displayName": "任一",
      "photoUrl": "",
      "userId": "04098430598358376154"
     },
     "user_tz": -480
    },
    "id": "ltAVKZ_V9MDF",
    "outputId": "96e09939-b6d9-44fe-af30-ae25fe12fb4f"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "net.to(device)\n",
    "predicted_label = list()\n",
    "groundTruth_label = list()\n",
    "corr = 0.0\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle = False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(tqdm(test_loader)):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        net.train(False)\n",
    "        outputs = net(inputs)\n",
    "        groundTruth_label.extend(labels.tolist())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted_label.extend(predicted.tolist())\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        corr += pearsonr(outputs[0].cpu(), test_labels_distribution[i])[0]\n",
    "    corr /= test_sentence_length\n",
    "print('\\nAccuracy of the network: %.4f %%' % (100 * correct / total))\n",
    "print('Macro F1 score: %.2f'%f1_score(groundTruth_label, predicted_label, average='macro'))\n",
    "print('Micro F1 score: %.2f'%f1_score(groundTruth_label, predicted_label, average='micro'))\n",
    "print('Corr:' , corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 150,
     "status": "ok",
     "timestamp": 1590419014057,
     "user": {
      "displayName": "任一",
      "photoUrl": "",
      "userId": "04098430598358376154"
     },
     "user_tz": -480
    },
    "id": "kIbOsl26UrT1",
    "outputId": "0c19d83f-dc96-45c2-fbd1-99f7d5748b8e"
   },
   "outputs": [],
   "source": [
    "print('Macro F1 score: %.3f'%f1_score(groundTruth_label, predicted_label, average='macro'))\n",
    "print('Micro F1 score: %.3f'%f1_score(groundTruth_label, predicted_label, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1346,
     "status": "ok",
     "timestamp": 1590419015268,
     "user": {
      "displayName": "任一",
      "photoUrl": "",
      "userId": "04098430598358376154"
     },
     "user_tz": -480
    },
    "id": "bihzL_SN9MDH",
    "outputId": "6ea1011f-bc73-4790-ade5-7fb87d4991d4"
   },
   "outputs": [],
   "source": [
    "acc_list = [100 * x for x in dev_acc_list[1:]]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "lns1 = ax.plot(epoch_list, acc_list, '-r', label='accuracy')\n",
    "ax2 = ax.twinx()\n",
    "lns2 = ax2.plot(epoch_list, loss_list, label = 'loss')\n",
    "lns = lns1 + lns2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax.legend(lns, labs, loc=0)\n",
    "ax.grid()\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('dev accuracy / %')\n",
    "ax2.set_ylabel('loss')\n",
    "ax.set_ylim(max(min(acc_list) - 10, 0), 100)\n",
    "ax2.set_ylim(np.mean(loss_list) - 2 * np.std(loss_list), np.mean(loss_list) + 2 * np.std(loss_list))\n",
    "plt.title('dev accuracy&loss epoch=%d lr=%f bs=%d maxacc=%.2f%%'%(max(epoch_list),lr,batch_size,max(acc_list)))\n",
    "# plt.savefig('./drive/My Drive/SentimentalClassification/code/pics/LSTMEpoch%dlr%fbatchsize%dmaxacc%.2f.jpg' % (max(epoch_list), lr, batch_size, max(acc_list)))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 186,
     "status": "ok",
     "timestamp": 1590419015416,
     "user": {
      "displayName": "任一",
      "photoUrl": "",
      "userId": "04098430598358376154"
     },
     "user_tz": -480
    },
    "id": "dpP53ueF9MDJ",
    "outputId": "49bda9d6-a4d6-46c1-c7bb-e94e3be9c47b"
   },
   "outputs": [],
   "source": [
    "# print(predicted_label)\n",
    "# print(groundTruth_label)\n",
    "# test_accuracy(train_loader, net, train_sentence_length)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_pretrain_cuda.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}