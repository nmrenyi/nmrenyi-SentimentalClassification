{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/data_train.csv')\n",
    "test_df = pd.read_csv('./data/data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = train_df['Text'].to_list()\n",
    "train_labels = train_df['MaxLabel'].to_list()\n",
    "test_corpus = test_df['Text'].to_list()\n",
    "test_labels = test_df['MaxLabel'].to_list()\n",
    "test_labels_distribution = test_df.iloc[:, 3:11].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/stopwords.txt', encoding='utf8') as f:\n",
    "    stop_words = [x.strip() for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectorizer = CountVectorizer(max_features=3000, stop_words=stop_words)\n",
    "train_X = train_vectorizer.fit_transform(train_corpus)\n",
    "train_feature_words = train_vectorizer.get_feature_names()\n",
    "train_feature_array = train_X.toarray()\n",
    "len(train_feature_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectorizer = CountVectorizer(vocabulary=train_feature_words)\n",
    "test_X = test_vectorizer.fit_transform(test_corpus)\n",
    "test_feature_array = test_X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_input(feature_array):\n",
    "    feature_tensor = torch.Tensor(feature_array).float()\n",
    "    max_tensor = torch.max(feature_tensor, dim=1)[0].unsqueeze(1)\n",
    "    return torch.div(feature_tensor, max_tensor).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feature_array = normalize_input(train_feature_array)\n",
    "# test_feature_array = normalize_input(test_feature_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "train_length = len(train_labels)\n",
    "mid = int(0.8 * train_length)\n",
    "train_set = torch.utils.data.TensorDataset(torch.tensor(train_feature_array[0:mid]).float(), torch.tensor(train_labels[0:mid]).long())\n",
    "test_set = torch.utils.data.TensorDataset(torch.tensor(test_feature_array).float(), torch.tensor(test_labels).long())\n",
    "dev_set = torch.utils.data.TensorDataset(torch.tensor(train_feature_array[mid:train_length]).float(), torch.tensor(train_labels[mid:train_length]).long())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_loader = torch.utils.data.DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
    "dev_loader = torch.utils.data.DataLoader(dev_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(len(train_feature_words), 8)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.softmax(x, dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(loader, net):\n",
    "    '''\n",
    "    used in dev set accuracy calculating\n",
    "    '''\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            inputs, label = data\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += label.size(0) # batch size\n",
    "\n",
    "            correct += (predicted == label).sum().item()\n",
    "    return correct / (0.0 + total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.005\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "model_path = './model/MLP_model_BOW.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dev_patience(acc_list, patience = 5):\n",
    "    if len(acc_list) <= patience:\n",
    "        return True\n",
    "    check_list = acc_list[len(acc_list)-patience:len(acc_list)]\n",
    "    for i in range(patience - 1):\n",
    "        if check_list[i] - check_list[i + 1] >= 0.01:\n",
    "            return False\n",
    "    if np.std(check_list) < 1e-4:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('before test', test_accuracy(test_loader, net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "loss_batch = 50\n",
    "dev_acc_list = [0] # initialize with a zero, easy to compare before first dev acc comes in\n",
    "loss_list = []\n",
    "epoch_list = []\n",
    "dev_patience = 5\n",
    "print('Start Training')\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    try:\n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % loss_batch == loss_batch - 1:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / loss_batch))\n",
    "                running_loss = 0.0\n",
    "    except KeyboardInterrupt:\n",
    "        exit_here = input('Early stop manually? (y/n) (default n)')\n",
    "        if exit_here.lower().startswith('y'):\n",
    "            print('Early stopped manually!')\n",
    "            break\n",
    "    finally:\n",
    "        dev_accuracy = test_accuracy(dev_loader, net)\n",
    "        print('epoch %d dev acc = %.2f' % (epoch + 1, dev_accuracy * 100))\n",
    "        if dev_accuracy > dev_acc_list[-1]:\n",
    "            print('New Model Saved!')\n",
    "            torch.save(net.state_dict(), model_path)\n",
    "\n",
    "        dev_acc_list.append(dev_accuracy)\n",
    "        loss_list.append(epoch_loss/train_length)\n",
    "        epoch_list.append(epoch + 1)\n",
    "        no_big_improve_on_dev = check_dev_patience(dev_acc_list, dev_patience)\n",
    "        if not no_big_improve_on_dev:\n",
    "            print('No significant improve on dev set, early stopped automatically!')\n",
    "            break\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "predicted_label = list()\n",
    "groundTruth_label = list()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(tqdm(test_loader)):\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        groundTruth_label.extend(labels.tolist())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted_label.extend(predicted.tolist())\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('\\nAccuracy of the network: %.4f %%' % (100 * correct / total))\n",
    "print('Macro F1 score: %.3f'%f1_score(groundTruth_label, predicted_label, average='macro'))\n",
    "print('Micro F1 score: %.3f'%f1_score(groundTruth_label, predicted_label, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle = False)\n",
    "corr = 0.0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(tqdm(test_loader)):\n",
    "        # inputs, labels = data\n",
    "        inputs, labels = data\n",
    "        net.train(False)\n",
    "        outputs = net(inputs)\n",
    "        corr += pearsonr(outputs[0].cpu(), test_labels_distribution[i])[0]\n",
    "    corr /= len(test_feature_array)\n",
    "print('\\nCorr:', corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list = [100 * x for x in dev_acc_list[1:]]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "lns1 = ax.plot(epoch_list, acc_list, '-r', label='accuracy')\n",
    "ax2 = ax.twinx()\n",
    "lns2 = ax2.plot(epoch_list, loss_list, label = 'loss')\n",
    "lns = lns1 + lns2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax.legend(lns, labs, loc=0)\n",
    "ax.grid()\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('dev accuracy / %')\n",
    "ax2.set_ylabel('loss')\n",
    "ax.set_ylim(max(min(acc_list) - 10, 0), 100)\n",
    "ax2.set_ylim(np.mean(loss_list) - 3 * np.std(loss_list), np.mean(loss_list) + 3 * np.std(loss_list))\n",
    "ax2.set_ylim(max(min(loss_list) - 1 * np.std(loss_list), 0), min(max(loss_list) + 1 * np.std(loss_list), 1))\n",
    "plt.title('dev accuracy&loss epoch=%d lr=%f bs=%d maxacc=%.2f%%'%(max(epoch_list),lr,batch_size,max(acc_list)))\n",
    "# plt.savefig('DevEpoch%dlr%fbatchsize%dmaxacc%.2f.jpg' % (max(epoch_list), lr, batch_size, max(acc_list)))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(groundTruth_label)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "编辑元数据",
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda17ad6249b02940119d559e8800b5bbf8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}